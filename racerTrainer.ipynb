{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 224, 224, 3)\n",
      "(380,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('trackTrainImages_210624.npy')\n",
    "y = np.load('trackPos_210624.npy')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize to range 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into a training set and a validation set\n",
    "X_train, X_valid = X_train[:-100], X_train[-100:]\n",
    "y_train, y_valid = y_train[:-100], y_train[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the MLP model\n",
    "inputs = Input(shape=(224,224,3))\n",
    "\n",
    "conv2D_1 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(inputs)\n",
    "maxPool_1 = MaxPooling2D(pool_size=2,strides=2)(conv2D_1)\n",
    "batch_1 = BatchNormalization()(maxPool_1)\n",
    "\n",
    "\n",
    "conv2D_2 = Conv2D(filters=15,kernel_size=2,strides=1,activation='relu')(batch_1)\n",
    "maxPool_2 = MaxPooling2D(pool_size=2,strides=1)(conv2D_2)\n",
    "batch_2 = BatchNormalization()(maxPool_2)\n",
    "\n",
    "conv2D_3 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(batch_2)\n",
    "maxPool_3 = MaxPooling2D(pool_size=2,strides=1)(conv2D_3)\n",
    "batch_3 = BatchNormalization()(maxPool_3)\n",
    "\n",
    "conv2D_4 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(batch_3)\n",
    "maxPool_4 = MaxPooling2D(pool_size=2,strides=1)(conv2D_4)\n",
    "batch_4 = BatchNormalization()(maxPool_4)\n",
    "\n",
    "\n",
    "flat = Flatten()(batch_4)\n",
    "dense_1 = Dense(units=64,activation='relu')(flat)\n",
    "outputs = Dense(units=1,activation='linear')(dense_1)\n",
    "\n",
    "model = keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 222, 222, 15)      420       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 15)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 111, 111, 15)      60        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 110, 110, 15)      915       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 109, 109, 15)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 109, 109, 15)      60        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 107, 107, 15)      2040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 106, 106, 15)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 106, 106, 15)      60        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 104, 104, 15)      2040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 103, 103, 15)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 103, 103, 15)      60        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 159135)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                10184704  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 10,190,424\n",
      "Trainable params: 10,190,304\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comile the model unsing categorical_crossentropy loss function\n",
    "model.compile(optimizer='nadam',loss='MSE',metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 204 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "204/204 [==============================] - 14s 71ms/sample - loss: 9322.3266 - mae: 69.7746 - mse: 9322.3262 - val_loss: 13304.6914 - val_mae: 98.6728 - val_mse: 13304.6924\n",
      "Epoch 2/100\n",
      "204/204 [==============================] - 13s 61ms/sample - loss: 1560.3952 - mae: 28.1174 - mse: 1560.3953 - val_loss: 11160.6271 - val_mae: 89.6848 - val_mse: 11160.6279\n",
      "Epoch 3/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 447.5368 - mae: 15.2857 - mse: 447.5368 - val_loss: 8774.2145 - val_mae: 79.4234 - val_mse: 8774.2139\n",
      "Epoch 4/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 122.2846 - mae: 8.3556 - mse: 122.2846 - val_loss: 7350.0418 - val_mae: 72.6183 - val_mse: 7350.0420\n",
      "Epoch 5/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 121.2322 - mae: 7.9095 - mse: 121.2322 - val_loss: 5969.1752 - val_mae: 65.2764 - val_mse: 5969.1748\n",
      "Epoch 6/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 85.6464 - mae: 6.4298 - mse: 85.6464 - val_loss: 5486.9024 - val_mae: 62.5021 - val_mse: 5486.9023\n",
      "Epoch 7/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 93.4931 - mae: 6.5906 - mse: 93.4931 - val_loss: 5463.5950 - val_mae: 62.3854 - val_mse: 5463.5952\n",
      "Epoch 8/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 147.6932 - mae: 7.4996 - mse: 147.6932 - val_loss: 4263.4501 - val_mae: 53.9903 - val_mse: 4263.4502\n",
      "Epoch 9/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 159.0292 - mae: 9.2212 - mse: 159.0292 - val_loss: 4224.2902 - val_mae: 53.7038 - val_mse: 4224.2900\n",
      "Epoch 10/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 213.5796 - mae: 10.5532 - mse: 213.5796 - val_loss: 3987.3975 - val_mae: 50.9735 - val_mse: 3987.3975\n",
      "Epoch 11/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 255.9569 - mae: 12.0037 - mse: 255.9569 - val_loss: 3953.8754 - val_mae: 48.9574 - val_mse: 3953.8757\n",
      "Epoch 12/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 494.1559 - mae: 17.1308 - mse: 494.1558 - val_loss: 3989.4668 - val_mae: 51.1643 - val_mse: 3989.4668\n",
      "Epoch 13/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 526.2331 - mae: 15.5007 - mse: 526.2331 - val_loss: 3911.7782 - val_mae: 50.0102 - val_mse: 3911.7781\n",
      "Epoch 14/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 261.1430 - mae: 11.6244 - mse: 261.1430 - val_loss: 3932.2645 - val_mae: 48.6658 - val_mse: 3932.2644\n",
      "Epoch 15/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 237.7145 - mae: 11.5721 - mse: 237.7145 - val_loss: 3880.9180 - val_mae: 48.7462 - val_mse: 3880.9182\n",
      "Epoch 16/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 773.2407 - mae: 21.7393 - mse: 773.2407 - val_loss: 5249.2591 - val_mae: 58.5013 - val_mse: 5249.2593\n",
      "Epoch 17/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 650.8910 - mae: 17.6177 - mse: 650.8910 - val_loss: 4136.2270 - val_mae: 50.3336 - val_mse: 4136.2271\n",
      "Epoch 18/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 392.1842 - mae: 12.7843 - mse: 392.1842 - val_loss: 7074.9248 - val_mae: 71.2778 - val_mse: 7074.9248\n",
      "Epoch 19/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 621.4198 - mae: 12.8965 - mse: 621.4199 - val_loss: 4858.4880 - val_mae: 55.9926 - val_mse: 4858.4883\n",
      "Epoch 20/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 453.1566 - mae: 8.8901 - mse: 453.1566 - val_loss: 3767.0444 - val_mae: 48.5795 - val_mse: 3767.0444\n",
      "Epoch 21/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 305.4155 - mae: 6.7586 - mse: 305.4155 - val_loss: 4052.4643 - val_mae: 49.8394 - val_mse: 4052.4644\n",
      "Epoch 22/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 288.4622 - mae: 6.4654 - mse: 288.4622 - val_loss: 3918.3893 - val_mae: 48.6273 - val_mse: 3918.3894\n",
      "Epoch 23/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 269.7662 - mae: 5.4246 - mse: 269.7662 - val_loss: 4305.6505 - val_mae: 52.2491 - val_mse: 4305.6504\n",
      "Epoch 24/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 505.9740 - mae: 12.1849 - mse: 505.9740 - val_loss: 3862.8647 - val_mae: 48.1906 - val_mse: 3862.8647\n",
      "Epoch 25/100\n",
      "204/204 [==============================] - 14s 66ms/sample - loss: 462.3164 - mae: 10.1521 - mse: 462.3164 - val_loss: 3606.7182 - val_mae: 46.4622 - val_mse: 3606.7180\n",
      "Epoch 26/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 386.5045 - mae: 9.5586 - mse: 386.5046 - val_loss: 4141.6784 - val_mae: 50.6725 - val_mse: 4141.6787\n",
      "Epoch 27/100\n",
      "204/204 [==============================] - 13s 64ms/sample - loss: 372.0957 - mae: 8.3879 - mse: 372.0957 - val_loss: 3935.7719 - val_mae: 48.8712 - val_mse: 3935.7720\n",
      "Epoch 28/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 387.4146 - mae: 8.4602 - mse: 387.4146 - val_loss: 5098.5846 - val_mae: 57.9163 - val_mse: 5098.5845\n",
      "Epoch 29/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 336.6844 - mae: 6.7113 - mse: 336.6844 - val_loss: 5604.8286 - val_mae: 61.2651 - val_mse: 5604.8286\n",
      "Epoch 30/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 1530.1838 - mae: 16.3264 - mse: 1530.1840 - val_loss: 5450.4744 - val_mae: 59.8027 - val_mse: 5450.4746\n",
      "Epoch 31/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 858.8720 - mae: 15.4482 - mse: 858.8719 - val_loss: 4715.2408 - val_mae: 54.6571 - val_mse: 4715.2407\n",
      "Epoch 32/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 421.1272 - mae: 8.9169 - mse: 421.1272 - val_loss: 3380.6938 - val_mae: 44.1604 - val_mse: 3380.6938\n",
      "Epoch 33/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 648.2892 - mae: 8.9141 - mse: 648.2891 - val_loss: 5719.9565 - val_mae: 61.6576 - val_mse: 5719.9561\n",
      "Epoch 34/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 647.1406 - mae: 10.6648 - mse: 647.1406 - val_loss: 5431.9548 - val_mae: 59.6982 - val_mse: 5431.9551\n",
      "Epoch 35/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 515.2138 - mae: 10.4838 - mse: 515.2137 - val_loss: 3104.9333 - val_mae: 42.1417 - val_mse: 3104.9331\n",
      "Epoch 36/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 397.5258 - mae: 9.0738 - mse: 397.5257 - val_loss: 3227.7303 - val_mae: 42.7960 - val_mse: 3227.7302\n",
      "Epoch 37/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 287.1887 - mae: 5.9160 - mse: 287.1886 - val_loss: 3076.4063 - val_mae: 41.7107 - val_mse: 3076.4062\n",
      "Epoch 38/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 252.0440 - mae: 4.0188 - mse: 252.0440 - val_loss: 3228.1867 - val_mae: 42.8849 - val_mse: 3228.1865\n",
      "Epoch 39/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 248.2202 - mae: 3.5765 - mse: 248.2202 - val_loss: 2917.5016 - val_mae: 40.3095 - val_mse: 2917.5015\n",
      "Epoch 40/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 246.1855 - mae: 3.4737 - mse: 246.1856 - val_loss: 3261.9713 - val_mae: 43.8809 - val_mse: 3261.9712\n",
      "Epoch 41/100\n",
      "204/204 [==============================] - 13s 64ms/sample - loss: 257.5917 - mae: 4.2650 - mse: 257.5917 - val_loss: 2878.9854 - val_mae: 40.3764 - val_mse: 2878.9854\n",
      "Epoch 42/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 247.8865 - mae: 3.4228 - mse: 247.8866 - val_loss: 2688.9585 - val_mae: 38.7876 - val_mse: 2688.9585\n",
      "Epoch 43/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 242.3252 - mae: 2.8618 - mse: 242.3252 - val_loss: 2483.0398 - val_mae: 37.2192 - val_mse: 2483.0398\n",
      "Epoch 44/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 255.6599 - mae: 4.0840 - mse: 255.6599 - val_loss: 2392.6978 - val_mae: 36.3074 - val_mse: 2392.6978\n",
      "Epoch 45/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 253.8784 - mae: 3.8424 - mse: 253.8784 - val_loss: 2263.5163 - val_mae: 35.0515 - val_mse: 2263.5164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 249.0081 - mae: 3.5070 - mse: 249.0081 - val_loss: 2171.2791 - val_mae: 34.5195 - val_mse: 2171.2791\n",
      "Epoch 47/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 243.1823 - mae: 2.8944 - mse: 243.1823 - val_loss: 2080.4432 - val_mae: 33.6098 - val_mse: 2080.4431\n",
      "Epoch 48/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 242.6576 - mae: 3.0192 - mse: 242.6576 - val_loss: 1910.7398 - val_mae: 32.4592 - val_mse: 1910.7399\n",
      "Epoch 49/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 244.0308 - mae: 3.0973 - mse: 244.0307 - val_loss: 1939.3257 - val_mae: 32.5232 - val_mse: 1939.3257\n",
      "Epoch 50/100\n",
      "204/204 [==============================] - 13s 61ms/sample - loss: 245.2074 - mae: 3.2924 - mse: 245.2074 - val_loss: 1813.2082 - val_mae: 32.2029 - val_mse: 1813.2081\n",
      "Epoch 51/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 265.3149 - mae: 4.7180 - mse: 265.3148 - val_loss: 1736.7491 - val_mae: 30.2945 - val_mse: 1736.7490\n",
      "Epoch 52/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 256.6999 - mae: 3.9442 - mse: 256.6999 - val_loss: 1674.7068 - val_mae: 29.8215 - val_mse: 1674.7067\n",
      "Epoch 53/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 246.2768 - mae: 3.5043 - mse: 246.2768 - val_loss: 1628.9836 - val_mae: 29.5135 - val_mse: 1628.9836\n",
      "Epoch 54/100\n",
      "204/204 [==============================] - 13s 61ms/sample - loss: 248.3163 - mae: 3.6675 - mse: 248.3163 - val_loss: 1633.5351 - val_mae: 29.4236 - val_mse: 1633.5352\n",
      "Epoch 55/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 267.0272 - mae: 4.3389 - mse: 267.0272 - val_loss: 1630.5519 - val_mae: 29.6129 - val_mse: 1630.5519\n",
      "Epoch 56/100\n",
      "204/204 [==============================] - 13s 61ms/sample - loss: 267.9846 - mae: 4.7440 - mse: 267.9846 - val_loss: 1529.8275 - val_mae: 28.8377 - val_mse: 1529.8275\n",
      "Epoch 57/100\n",
      "204/204 [==============================] - 13s 61ms/sample - loss: 258.0670 - mae: 4.1740 - mse: 258.0670 - val_loss: 1473.5144 - val_mae: 28.1224 - val_mse: 1473.5144\n",
      "Epoch 58/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 262.1235 - mae: 5.0956 - mse: 262.1235 - val_loss: 1477.6350 - val_mae: 27.7900 - val_mse: 1477.6350\n",
      "Epoch 59/100\n",
      "204/204 [==============================] - 13s 61ms/sample - loss: 251.2483 - mae: 3.9241 - mse: 251.2483 - val_loss: 1589.3994 - val_mae: 30.4402 - val_mse: 1589.3994\n",
      "Epoch 60/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 254.3224 - mae: 4.0912 - mse: 254.3224 - val_loss: 1533.0494 - val_mae: 28.8617 - val_mse: 1533.0496\n",
      "Epoch 61/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 254.9324 - mae: 3.9939 - mse: 254.9323 - val_loss: 1427.8022 - val_mae: 28.7962 - val_mse: 1427.8022\n",
      "Epoch 62/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 266.1117 - mae: 4.5878 - mse: 266.1117 - val_loss: 1523.9211 - val_mae: 28.5695 - val_mse: 1523.9211\n",
      "Epoch 63/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 260.8853 - mae: 4.5961 - mse: 260.8853 - val_loss: 1457.0025 - val_mae: 27.3967 - val_mse: 1457.0024\n",
      "Epoch 64/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 261.8261 - mae: 4.4722 - mse: 261.8261 - val_loss: 1548.0148 - val_mae: 28.9696 - val_mse: 1548.0149\n",
      "Epoch 65/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 263.1424 - mae: 4.7988 - mse: 263.1424 - val_loss: 1477.3133 - val_mae: 27.9322 - val_mse: 1477.3131\n",
      "Epoch 66/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 263.4859 - mae: 4.8623 - mse: 263.4859 - val_loss: 1524.7406 - val_mae: 29.3606 - val_mse: 1524.7406\n",
      "Epoch 67/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 282.3212 - mae: 6.5181 - mse: 282.3212 - val_loss: 1523.8326 - val_mae: 28.1237 - val_mse: 1523.8326\n",
      "Epoch 68/100\n",
      "204/204 [==============================] - 14s 66ms/sample - loss: 278.3552 - mae: 5.4252 - mse: 278.3552 - val_loss: 2163.3020 - val_mae: 34.2720 - val_mse: 2163.3020\n",
      "Epoch 69/100\n",
      "204/204 [==============================] - 13s 66ms/sample - loss: 487.4871 - mae: 11.1327 - mse: 487.4871 - val_loss: 1558.8346 - val_mae: 27.9515 - val_mse: 1558.8345\n",
      "Epoch 70/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 426.0195 - mae: 10.2544 - mse: 426.0194 - val_loss: 1843.0989 - val_mae: 34.9183 - val_mse: 1843.0988\n",
      "Epoch 71/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 484.9319 - mae: 11.2140 - mse: 484.9319 - val_loss: 2410.4712 - val_mae: 41.4495 - val_mse: 2410.4712\n",
      "Epoch 72/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 431.4990 - mae: 10.4900 - mse: 431.4990 - val_loss: 1392.3777 - val_mae: 27.4520 - val_mse: 1392.3777\n",
      "Epoch 73/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 307.9409 - mae: 6.7665 - mse: 307.9409 - val_loss: 1397.9792 - val_mae: 29.9095 - val_mse: 1397.9792\n",
      "Epoch 74/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 303.6739 - mae: 6.9905 - mse: 303.6739 - val_loss: 1190.4723 - val_mae: 25.2341 - val_mse: 1190.4723\n",
      "Epoch 75/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 325.2834 - mae: 6.8680 - mse: 325.2834 - val_loss: 1448.8954 - val_mae: 28.1935 - val_mse: 1448.8953\n",
      "Epoch 76/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 280.3117 - mae: 5.2154 - mse: 280.3116 - val_loss: 1272.1376 - val_mae: 26.1149 - val_mse: 1272.1376\n",
      "Epoch 77/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 255.0009 - mae: 4.1497 - mse: 255.0009 - val_loss: 1566.4017 - val_mae: 28.0491 - val_mse: 1566.4016\n",
      "Epoch 78/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 263.7790 - mae: 4.1114 - mse: 263.7790 - val_loss: 1119.6220 - val_mae: 24.3196 - val_mse: 1119.6218\n",
      "Epoch 79/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 258.5392 - mae: 3.8280 - mse: 258.5392 - val_loss: 1355.6034 - val_mae: 26.7028 - val_mse: 1355.6034\n",
      "Epoch 80/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 264.1130 - mae: 4.1528 - mse: 264.1130 - val_loss: 1281.7433 - val_mae: 26.3519 - val_mse: 1281.7434\n",
      "Epoch 81/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 260.7724 - mae: 4.5013 - mse: 260.7724 - val_loss: 1666.4202 - val_mae: 29.2023 - val_mse: 1666.4203\n",
      "Epoch 82/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 346.0343 - mae: 6.9077 - mse: 346.0342 - val_loss: 1288.4548 - val_mae: 26.0266 - val_mse: 1288.4547\n",
      "Epoch 83/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 287.9526 - mae: 5.7639 - mse: 287.9526 - val_loss: 1411.2465 - val_mae: 27.6690 - val_mse: 1411.2466\n",
      "Epoch 84/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 271.9340 - mae: 5.1195 - mse: 271.9340 - val_loss: 1261.1280 - val_mae: 25.6810 - val_mse: 1261.1279\n",
      "Epoch 85/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 258.4793 - mae: 4.2302 - mse: 258.4794 - val_loss: 1227.6824 - val_mae: 25.1358 - val_mse: 1227.6824\n",
      "Epoch 86/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 257.5046 - mae: 4.3292 - mse: 257.5046 - val_loss: 1315.4058 - val_mae: 25.9543 - val_mse: 1315.4058\n",
      "Epoch 87/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 271.2222 - mae: 4.1132 - mse: 271.2222 - val_loss: 1490.0276 - val_mae: 27.8995 - val_mse: 1490.0275\n",
      "Epoch 88/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 305.9439 - mae: 5.3801 - mse: 305.9438 - val_loss: 1229.0975 - val_mae: 27.2299 - val_mse: 1229.0975\n",
      "Epoch 89/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 299.1289 - mae: 6.3677 - mse: 299.1289 - val_loss: 1220.5848 - val_mae: 27.4096 - val_mse: 1220.5847\n",
      "Epoch 90/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 429.0740 - mae: 9.1345 - mse: 429.0740 - val_loss: 1237.4419 - val_mae: 26.5351 - val_mse: 1237.4419\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 13s 63ms/sample - loss: 357.6769 - mae: 7.9159 - mse: 357.6769 - val_loss: 1323.7666 - val_mae: 27.5767 - val_mse: 1323.7666\n",
      "Epoch 92/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 277.5539 - mae: 5.3071 - mse: 277.5539 - val_loss: 1339.3157 - val_mae: 26.3479 - val_mse: 1339.3158\n",
      "Epoch 93/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 255.3907 - mae: 4.2486 - mse: 255.3907 - val_loss: 1370.3949 - val_mae: 26.5500 - val_mse: 1370.3950\n",
      "Epoch 94/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 270.9774 - mae: 5.1320 - mse: 270.9774 - val_loss: 1557.2434 - val_mae: 28.0555 - val_mse: 1557.2434\n",
      "Epoch 95/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 315.9547 - mae: 7.0249 - mse: 315.9547 - val_loss: 1296.1447 - val_mae: 27.3064 - val_mse: 1296.1447\n",
      "Epoch 96/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 274.5341 - mae: 5.2222 - mse: 274.5341 - val_loss: 1278.7981 - val_mae: 26.0178 - val_mse: 1278.7981\n",
      "Epoch 97/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 254.0318 - mae: 4.1976 - mse: 254.0318 - val_loss: 1462.8347 - val_mae: 27.2972 - val_mse: 1462.8347\n",
      "Epoch 98/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 259.2566 - mae: 4.0327 - mse: 259.2566 - val_loss: 1452.3569 - val_mae: 27.1679 - val_mse: 1452.3571\n",
      "Epoch 99/100\n",
      "204/204 [==============================] - 13s 62ms/sample - loss: 251.3146 - mae: 3.6129 - mse: 251.3146 - val_loss: 1434.5021 - val_mae: 26.4286 - val_mse: 1434.5022\n",
      "Epoch 100/100\n",
      "204/204 [==============================] - 13s 63ms/sample - loss: 246.9267 - mae: 3.3008 - mse: 246.9267 - val_loss: 1398.7026 - val_mae: 26.2766 - val_mse: 1398.7025\n"
     ]
    }
   ],
   "source": [
    "# train the model using a mini batch size of 100 images and 50 epochs\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=20,validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "76/76 [==============================] - 2s 27ms/sample - loss: 1046.5554 - mae: 22.1079 - mse: 1046.5554\n",
      "test loss, test mse: [1046.555419921875, 22.10793, 1046.5554]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(X_test, y_test, batch_size=100)\n",
    "print('test loss, test mse:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy and loss as a function of the epochs\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('loss', color=color)\n",
    "ax1.plot(history.history['loss'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('mse', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(history.history['mse'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual : 142.0 -- Pres : [146.46754]\n",
      "Actual : 79.0 -- Pres : [79.35663]\n",
      "Actual : 126.0 -- Pres : [126.552315]\n",
      "Actual : 82.0 -- Pres : [81.59377]\n",
      "Actual : 99.0 -- Pres : [98.37879]\n",
      "Actual : 83.0 -- Pres : [85.98033]\n",
      "Actual : 49.0 -- Pres : [47.468544]\n",
      "Actual : 167.0 -- Pres : [170.80647]\n",
      "Actual : 147.0 -- Pres : [148.08017]\n",
      "Actual : 170.0 -- Pres : [176.85469]\n",
      "Actual : 94.0 -- Pres : [93.64587]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 118.3 -- Pres : [120.40989]\n",
      "Actual : 104.0 -- Pres : [103.626305]\n",
      "Actual : 197.0 -- Pres : [199.07478]\n",
      "Actual : 118.3 -- Pres : [120.18164]\n",
      "Actual : 62.0 -- Pres : [60.81077]\n",
      "Actual : 46.0 -- Pres : [43.14959]\n",
      "Actual : 81.0 -- Pres : [78.93516]\n",
      "Actual : 56.0 -- Pres : [44.887054]\n",
      "Actual : 120.0 -- Pres : [119.510124]\n",
      "Actual : 185.0 -- Pres : [191.55943]\n",
      "Actual : 207.0 -- Pres : [207.76208]\n",
      "Actual : 112.0 -- Pres : [111.3392]\n",
      "Actual : 137.0 -- Pres : [139.8619]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 33.0 -- Pres : [32.201614]\n",
      "Actual : 219.5 -- Pres : [226.30602]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 219.5 -- Pres : [225.04839]\n",
      "Actual : 118.3 -- Pres : [121.28276]\n",
      "Actual : 153.0 -- Pres : [157.65787]\n",
      "Actual : 118.3 -- Pres : [120.062035]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 104.0 -- Pres : [104.00761]\n",
      "Actual : 189.0 -- Pres : [187.61574]\n",
      "Actual : 98.0 -- Pres : [98.71025]\n",
      "Actual : 147.4 -- Pres : [150.26576]\n",
      "Actual : 72.0 -- Pres : [70.99314]\n",
      "Actual : 112.0 -- Pres : [114.939766]\n",
      "Actual : 208.9 -- Pres : [208.96437]\n",
      "Actual : 225.0 -- Pres : [226.87958]\n",
      "Actual : 66.0 -- Pres : [65.150925]\n",
      "Actual : 219.5 -- Pres : [220.54991]\n",
      "Actual : 82.0 -- Pres : [80.84478]\n",
      "Actual : 83.0 -- Pres : [85.00295]\n",
      "Actual : 110.0 -- Pres : [110.83019]\n",
      "Actual : 99.0 -- Pres : [99.957344]\n",
      "Actual : 184.0 -- Pres : [185.55475]\n",
      "Actual : 118.3 -- Pres : [119.54359]\n",
      "Actual : 219.5 -- Pres : [0.09212313]\n",
      "Actual : 104.0 -- Pres : [104.56573]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 219.0 -- Pres : [226.00487]\n",
      "Actual : 218.0 -- Pres : [221.77225]\n",
      "Actual : 118.3 -- Pres : [121.697395]\n",
      "Actual : 101.0 -- Pres : [101.39808]\n",
      "Actual : 133.0 -- Pres : [135.40471]\n",
      "Actual : 42.0 -- Pres : [41.7117]\n",
      "Actual : 37.0 -- Pres : [37.616875]\n",
      "Actual : 143.0 -- Pres : [144.57405]\n",
      "Actual : 96.0 -- Pres : [96.25697]\n",
      "Actual : 219.5 -- Pres : [222.47104]\n",
      "Actual : 118.3 -- Pres : [118.988914]\n",
      "Actual : 87.0 -- Pres : [86.52381]\n",
      "Actual : 166.0 -- Pres : [163.53154]\n",
      "Actual : 118.3 -- Pres : [120.45195]\n",
      "Actual : 69.0 -- Pres : [69.03011]\n",
      "Actual : 144.0 -- Pres : [142.6637]\n",
      "Actual : 84.0 -- Pres : [82.90621]\n",
      "Actual : 122.0 -- Pres : [121.83538]\n",
      "Actual : 72.0 -- Pres : [71.48079]\n",
      "Actual : 16.0 -- Pres : [17.000948]\n",
      "Actual : 51.0 -- Pres : [50.131554]\n",
      "Actual : 206.0 -- Pres : [210.05562]\n",
      "Actual : 219.5 -- Pres : [225.88478]\n",
      "Actual : 152.0 -- Pres : [153.52296]\n",
      "Actual : 67.0 -- Pres : [65.98456]\n",
      "Actual : 219.5 -- Pres : [220.79688]\n",
      "Actual : 49.0 -- Pres : [49.88289]\n",
      "Actual : 100.0 -- Pres : [99.8605]\n",
      "Actual : 122.0 -- Pres : [123.65722]\n",
      "Actual : 95.0 -- Pres : [94.969826]\n",
      "Actual : 69.0 -- Pres : [70.586006]\n",
      "Actual : 219.5 -- Pres : [221.69597]\n",
      "Actual : 225.0 -- Pres : [223.73322]\n",
      "Actual : 69.6 -- Pres : [70.63804]\n",
      "Actual : 124.0 -- Pres : [126.61069]\n",
      "Actual : 104.0 -- Pres : [106.11576]\n",
      "Actual : 118.3 -- Pres : [121.72992]\n",
      "Actual : 118.3 -- Pres : [123.30227]\n",
      "Actual : 219.5 -- Pres : [218.4999]\n",
      "Actual : 105.0 -- Pres : [106.80213]\n",
      "Actual : 100.0 -- Pres : [98.94065]\n",
      "Actual : 46.0 -- Pres : [45.531578]\n",
      "Actual : 123.0 -- Pres : [123.48007]\n",
      "Actual : 108.0 -- Pres : [107.37511]\n",
      "Actual : 157.0 -- Pres : [164.4529]\n",
      "Actual : 54.0 -- Pres : [53.671013]\n",
      "Actual : 47.0 -- Pres : [46.105106]\n",
      "Actual : 219.5 -- Pres : [230.57228]\n",
      "Actual : 78.0 -- Pres : [77.00849]\n",
      "Actual : 139.0 -- Pres : [143.32709]\n",
      "Actual : 103.0 -- Pres : [102.43267]\n",
      "Actual : 94.0 -- Pres : [92.87307]\n",
      "Actual : 102.0 -- Pres : [103.86395]\n",
      "Actual : 27.0 -- Pres : [25.406664]\n",
      "Actual : 225.0 -- Pres : [229.93584]\n",
      "Actual : 40.0 -- Pres : [37.677177]\n",
      "Actual : 124.0 -- Pres : [127.03988]\n",
      "Actual : 81.0 -- Pres : [80.329475]\n",
      "Actual : 73.0 -- Pres : [73.51269]\n",
      "Actual : 80.0 -- Pres : [80.676414]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 118.3 -- Pres : [123.199196]\n",
      "Actual : 118.3 -- Pres : [119.94553]\n",
      "Actual : 7.0 -- Pres : [0.09212313]\n",
      "Actual : 37.8 -- Pres : [37.170696]\n",
      "Actual : 86.0 -- Pres : [85.78708]\n",
      "Actual : 81.0 -- Pres : [84.47755]\n",
      "Actual : 60.0 -- Pres : [59.669518]\n",
      "Actual : 15.0 -- Pres : [14.276695]\n",
      "Actual : 135.0 -- Pres : [137.80074]\n",
      "Actual : 127.0 -- Pres : [129.49432]\n",
      "Actual : 188.0 -- Pres : [187.25568]\n",
      "Actual : 54.0 -- Pres : [53.2742]\n",
      "Actual : 118.0 -- Pres : [119.63062]\n",
      "Actual : 31.0 -- Pres : [31.137836]\n",
      "Actual : 219.5 -- Pres : [224.70894]\n",
      "Actual : 62.0 -- Pres : [61.84252]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 219.5 -- Pres : [224.03993]\n",
      "Actual : 131.0 -- Pres : [135.3373]\n",
      "Actual : 108.0 -- Pres : [106.841606]\n",
      "Actual : 208.0 -- Pres : [212.47871]\n",
      "Actual : 119.0 -- Pres : [121.04856]\n",
      "Actual : 90.0 -- Pres : [88.88585]\n",
      "Actual : 112.0 -- Pres : [117.729774]\n",
      "Actual : 75.0 -- Pres : [73.99299]\n",
      "Actual : 84.0 -- Pres : [83.425575]\n",
      "Actual : 118.3 -- Pres : [121.24923]\n",
      "Actual : 104.0 -- Pres : [105.06545]\n",
      "Actual : 225.0 -- Pres : [223.55318]\n",
      "Actual : 59.0 -- Pres : [58.256393]\n",
      "Actual : 137.0 -- Pres : [141.71736]\n",
      "Actual : 113.0 -- Pres : [112.96827]\n",
      "Actual : 4.0 -- Pres : [3.4116125]\n",
      "Actual : 168.0 -- Pres : [173.60248]\n",
      "Actual : 200.0 -- Pres : [205.74246]\n",
      "Actual : 118.3 -- Pres : [119.86158]\n",
      "Actual : 97.0 -- Pres : [98.29119]\n",
      "Actual : 151.0 -- Pres : [154.69733]\n",
      "Actual : 113.0 -- Pres : [114.56154]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 102.0 -- Pres : [102.46654]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 37.0 -- Pres : [35.961433]\n",
      "Actual : 87.0 -- Pres : [87.98266]\n",
      "Actual : 118.3 -- Pres : [122.92701]\n",
      "Actual : 189.0 -- Pres : [190.96994]\n",
      "Actual : 104.0 -- Pres : [103.21492]\n",
      "Actual : 96.0 -- Pres : [102.12667]\n",
      "Actual : 126.0 -- Pres : [124.99804]\n",
      "Actual : 34.0 -- Pres : [33.722927]\n",
      "Actual : 138.0 -- Pres : [142.0988]\n",
      "Actual : 219.5 -- Pres : [220.05016]\n",
      "Actual : 118.3 -- Pres : [122.2954]\n",
      "Actual : 118.3 -- Pres : [122.21427]\n",
      "Actual : 118.3 -- Pres : [120.007866]\n",
      "Actual : 46.0 -- Pres : [43.46174]\n",
      "Actual : 219.5 -- Pres : [221.06242]\n",
      "Actual : 184.0 -- Pres : [186.01949]\n",
      "Actual : 30.0 -- Pres : [29.83742]\n",
      "Actual : 219.5 -- Pres : [222.36584]\n",
      "Actual : 44.0 -- Pres : [42.45895]\n",
      "Actual : 75.0 -- Pres : [75.21688]\n",
      "Actual : 0.0 -- Pres : [0.09212313]\n",
      "Actual : 80.0 -- Pres : [80.90444]\n",
      "Actual : 181.0 -- Pres : [184.7765]\n",
      "Actual : 116.0 -- Pres : [117.72448]\n",
      "Actual : 64.0 -- Pres : [63.358055]\n",
      "Actual : 128.0 -- Pres : [130.93932]\n",
      "Actual : 225.0 -- Pres : [225.12341]\n",
      "Actual : 65.0 -- Pres : [63.974876]\n",
      "Actual : 118.3 -- Pres : [120.65574]\n",
      "Actual : 57.0 -- Pres : [56.322773]\n",
      "Actual : 56.0 -- Pres : [55.60183]\n",
      "Actual : 14.0 -- Pres : [13.641599]\n",
      "Actual : 101.0 -- Pres : [102.6049]\n",
      "Actual : 118.0 -- Pres : [118.977196]\n",
      "Actual : 4.0 -- Pres : [3.3813028]\n",
      "Actual : 101.0 -- Pres : [101.26943]\n",
      "Actual : 116.0 -- Pres : [118.21517]\n",
      "Actual : 44.0 -- Pres : [41.659794]\n",
      "Actual : 97.0 -- Pres : [96.6939]\n",
      "Actual : 59.0 -- Pres : [58.964043]\n",
      "Actual : 44.0 -- Pres : [43.939316]\n",
      "Actual : 70.0 -- Pres : [69.2676]\n",
      "Actual : 66.0 -- Pres : [65.73126]\n",
      "Actual : 132.0 -- Pres : [131.97423]\n",
      "Actual : 118.3 -- Pres : [121.22354]\n",
      "Actual : 118.3 -- Pres : [122.3041]\n",
      "Actual : 47.0 -- Pres : [46.271282]\n",
      "Actual : 128.0 -- Pres : [128.1964]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_train)):\n",
    "    \n",
    "    print('Actual : '+ str(y_train[i])+' -- Pres : '+str(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('racerModel_210624.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.array([X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.16452"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vince/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.16452"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = new_model.predict(XX)\n",
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
