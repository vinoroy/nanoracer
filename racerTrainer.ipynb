{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 20, 224, 3)\n",
      "(550,)\n"
     ]
    }
   ],
   "source": [
    "#X = np.load('trackTrainImages_210624.npy')\n",
    "#y = np.load('trackPos_210624.npy')\n",
    "\n",
    "X = np.load('trackTrainImages.npy')\n",
    "y = np.load('trackPos.npy')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtemp = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "\n",
    "    Xtemp.append(X[i][100:200])\n",
    "    \n",
    "XX = np.array(Xtemp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 20, 224, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "\n",
    "X_test = X\n",
    "y_test = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize to range 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into a training set and a validation set\n",
    "X_train, X_valid = X_train[:-100], X_train[-100:]\n",
    "y_train, y_valid = y_train[:-100], y_train[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 100, 224, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the MLP model\n",
    "inputs = Input(shape=(20,224,3))\n",
    "\n",
    "conv2D_1 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(inputs)\n",
    "maxPool_1 = MaxPooling2D(pool_size=2,strides=2)(conv2D_1)\n",
    "batch_1 = BatchNormalization()(maxPool_1)\n",
    "\n",
    "\n",
    "conv2D_2 = Conv2D(filters=15,kernel_size=2,strides=1,activation='relu')(batch_1)\n",
    "maxPool_2 = MaxPooling2D(pool_size=2,strides=1)(conv2D_2)\n",
    "batch_2 = BatchNormalization()(maxPool_2)\n",
    "\n",
    "conv2D_3 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(batch_2)\n",
    "maxPool_3 = MaxPooling2D(pool_size=2,strides=1)(conv2D_3)\n",
    "batch_3 = BatchNormalization()(maxPool_3)\n",
    "\n",
    "conv2D_4 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(batch_3)\n",
    "maxPool_4 = MaxPooling2D(pool_size=2,strides=1)(conv2D_4)\n",
    "batch_4 = BatchNormalization()(maxPool_4)\n",
    "\n",
    "\n",
    "flat = Flatten()(batch_4)\n",
    "dense_1 = Dense(units=64,activation='relu')(flat)\n",
    "outputs = Dense(units=1,activation='linear')(dense_1)\n",
    "\n",
    "model = keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 20, 224, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 222, 15)       420       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 111, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 9, 111, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 110, 15)        915       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 109, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 109, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 107, 15)        2040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 106, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 106, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 104, 15)        2040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 103, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 103, 15)        60        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1545)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                98944     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 104,664\n",
      "Trainable params: 104,544\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comile the model unsing categorical_crossentropy loss function\n",
    "model.compile(optimizer='nadam',loss='MSE',metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 100 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[20,15,9,111] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_9/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss_2/mul/_613]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[20,15,9,111] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_9/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model using a mini batch size of 100 images and 50 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[20,15,9,111] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_9/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss_2/mul/_613]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[20,15,9,111] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_9/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "# train the model using a mini batch size of 100 images and 50 epochs\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=20,validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "550/550 [==============================] - 3s 5ms/sample - loss: 69.1333 - mean_absolute_error: 5.3561 - mean_squared_error: 69.1333\n",
      "test loss, test mse: [69.13332479650325, 5.356071, 69.13332]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(X_test, y_test, batch_size=100)\n",
    "print('test loss, test mse:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tab:blue'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# we already handled the x-label with ax1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mse'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e95f748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy and loss as a function of the epochs\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('loss', color=color)\n",
    "ax1.plot(history.history['loss'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('mse', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(history.history['mse'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual : 107.0 -- Pres : [109.14441]\n",
      "Actual : 107.6 -- Pres : [109.74423]\n",
      "Actual : 107.6 -- Pres : [107.86649]\n",
      "Actual : 107.6 -- Pres : [107.044975]\n",
      "Actual : 107.6 -- Pres : [107.71019]\n",
      "Actual : 107.6 -- Pres : [108.222015]\n",
      "Actual : 107.6 -- Pres : [108.60607]\n",
      "Actual : 107.6 -- Pres : [106.16433]\n",
      "Actual : 107.6 -- Pres : [108.107834]\n",
      "Actual : 107.6 -- Pres : [105.370674]\n",
      "Actual : 107.6 -- Pres : [106.39687]\n",
      "Actual : 107.6 -- Pres : [106.042175]\n",
      "Actual : 107.6 -- Pres : [106.27174]\n",
      "Actual : 107.6 -- Pres : [106.18567]\n",
      "Actual : 107.6 -- Pres : [105.82971]\n",
      "Actual : 107.6 -- Pres : [107.30092]\n",
      "Actual : 107.6 -- Pres : [107.71571]\n",
      "Actual : 107.6 -- Pres : [108.96794]\n",
      "Actual : 107.6 -- Pres : [109.32758]\n",
      "Actual : 107.6 -- Pres : [106.8824]\n",
      "Actual : 107.6 -- Pres : [107.69978]\n",
      "Actual : 107.6 -- Pres : [106.090675]\n",
      "Actual : 107.6 -- Pres : [108.41795]\n",
      "Actual : 109.0 -- Pres : [110.19004]\n",
      "Actual : 109.0 -- Pres : [110.74855]\n",
      "Actual : 103.0 -- Pres : [100.875854]\n",
      "Actual : 93.0 -- Pres : [92.41871]\n",
      "Actual : 86.0 -- Pres : [87.49726]\n",
      "Actual : 82.0 -- Pres : [82.2595]\n",
      "Actual : 78.0 -- Pres : [79.00188]\n",
      "Actual : 76.0 -- Pres : [73.63524]\n",
      "Actual : 67.0 -- Pres : [68.27771]\n",
      "Actual : 59.0 -- Pres : [61.291115]\n",
      "Actual : 53.0 -- Pres : [58.779686]\n",
      "Actual : 51.0 -- Pres : [56.50554]\n",
      "Actual : 46.0 -- Pres : [53.42141]\n",
      "Actual : 42.0 -- Pres : [45.26347]\n",
      "Actual : 40.0 -- Pres : [41.756577]\n",
      "Actual : 36.0 -- Pres : [36.121826]\n",
      "Actual : 34.0 -- Pres : [37.434742]\n",
      "Actual : 33.0 -- Pres : [34.805435]\n",
      "Actual : 32.0 -- Pres : [37.314053]\n",
      "Actual : 29.0 -- Pres : [29.56098]\n",
      "Actual : 29.6 -- Pres : [28.68404]\n",
      "Actual : 27.0 -- Pres : [23.437582]\n",
      "Actual : 27.1 -- Pres : [21.997423]\n",
      "Actual : 27.1 -- Pres : [30.940506]\n",
      "Actual : 27.1 -- Pres : [31.844141]\n",
      "Actual : 27.1 -- Pres : [27.320633]\n",
      "Actual : 23.0 -- Pres : [24.94331]\n",
      "Actual : 21.0 -- Pres : [20.972443]\n",
      "Actual : 16.0 -- Pres : [20.314821]\n",
      "Actual : 14.0 -- Pres : [16.8758]\n",
      "Actual : 14.0 -- Pres : [18.76866]\n",
      "Actual : 19.0 -- Pres : [21.38512]\n",
      "Actual : 17.0 -- Pres : [14.330173]\n",
      "Actual : 19.0 -- Pres : [15.722163]\n",
      "Actual : 15.0 -- Pres : [14.127177]\n",
      "Actual : 15.1 -- Pres : [14.68525]\n",
      "Actual : 15.1 -- Pres : [14.6735735]\n",
      "Actual : 15.1 -- Pres : [17.793585]\n",
      "Actual : 15.1 -- Pres : [16.597534]\n",
      "Actual : 13.0 -- Pres : [14.322061]\n",
      "Actual : 13.4 -- Pres : [13.907788]\n",
      "Actual : 13.4 -- Pres : [13.766308]\n",
      "Actual : 13.4 -- Pres : [13.663371]\n",
      "Actual : 13.4 -- Pres : [15.613751]\n",
      "Actual : 13.4 -- Pres : [14.5868845]\n",
      "Actual : 13.4 -- Pres : [14.63409]\n",
      "Actual : 11.0 -- Pres : [8.951251]\n",
      "Actual : 11.8 -- Pres : [10.037223]\n",
      "Actual : 11.8 -- Pres : [11.921062]\n",
      "Actual : 11.8 -- Pres : [11.774654]\n",
      "Actual : 16.0 -- Pres : [16.504642]\n",
      "Actual : 14.0 -- Pres : [12.929246]\n",
      "Actual : 14.0 -- Pres : [13.258896]\n",
      "Actual : 13.0 -- Pres : [12.866634]\n",
      "Actual : 13.6 -- Pres : [13.875698]\n",
      "Actual : 13.6 -- Pres : [13.093074]\n",
      "Actual : 18.0 -- Pres : [15.762158]\n",
      "Actual : 18.1 -- Pres : [16.646408]\n",
      "Actual : 18.1 -- Pres : [14.906796]\n",
      "Actual : 18.1 -- Pres : [19.67423]\n",
      "Actual : 18.1 -- Pres : [20.676788]\n",
      "Actual : 21.0 -- Pres : [20.726532]\n",
      "Actual : 21.0 -- Pres : [25.370115]\n",
      "Actual : 21.0 -- Pres : [24.60816]\n",
      "Actual : 21.0 -- Pres : [25.014727]\n",
      "Actual : 24.0 -- Pres : [27.721695]\n",
      "Actual : 24.7 -- Pres : [28.276772]\n",
      "Actual : 26.0 -- Pres : [26.133345]\n",
      "Actual : 26.1 -- Pres : [27.36389]\n",
      "Actual : 26.0 -- Pres : [32.330387]\n",
      "Actual : 26.7 -- Pres : [34.31477]\n",
      "Actual : 30.0 -- Pres : [34.223763]\n",
      "Actual : 30.4 -- Pres : [34.629448]\n",
      "Actual : 33.0 -- Pres : [39.87751]\n",
      "Actual : 33.3 -- Pres : [37.67828]\n",
      "Actual : 36.0 -- Pres : [40.046276]\n",
      "Actual : 36.2 -- Pres : [39.398758]\n",
      "Actual : 39.0 -- Pres : [44.613625]\n",
      "Actual : 39.0 -- Pres : [43.870327]\n",
      "Actual : 39.0 -- Pres : [42.332348]\n",
      "Actual : 41.0 -- Pres : [49.60672]\n",
      "Actual : 46.0 -- Pres : [53.750988]\n",
      "Actual : 48.0 -- Pres : [58.16825]\n",
      "Actual : 50.0 -- Pres : [53.34181]\n",
      "Actual : 54.0 -- Pres : [55.463726]\n",
      "Actual : 57.0 -- Pres : [58.15875]\n",
      "Actual : 61.0 -- Pres : [62.800694]\n",
      "Actual : 61.0 -- Pres : [64.04804]\n",
      "Actual : 61.6 -- Pres : [63.11606]\n",
      "Actual : 61.6 -- Pres : [68.297455]\n",
      "Actual : 69.0 -- Pres : [70.98432]\n",
      "Actual : 73.0 -- Pres : [74.68089]\n",
      "Actual : 77.0 -- Pres : [83.6912]\n",
      "Actual : 78.0 -- Pres : [81.481514]\n",
      "Actual : 81.0 -- Pres : [83.78731]\n",
      "Actual : 86.0 -- Pres : [87.395256]\n",
      "Actual : 91.0 -- Pres : [94.7982]\n",
      "Actual : 95.0 -- Pres : [97.70564]\n",
      "Actual : 100.0 -- Pres : [104.60251]\n",
      "Actual : 104.0 -- Pres : [110.924286]\n",
      "Actual : 108.0 -- Pres : [114.64675]\n",
      "Actual : 109.0 -- Pres : [114.127205]\n",
      "Actual : 109.0 -- Pres : [114.230934]\n",
      "Actual : 115.0 -- Pres : [119.39734]\n",
      "Actual : 115.2 -- Pres : [121.57142]\n",
      "Actual : 115.2 -- Pres : [120.37246]\n",
      "Actual : 115.2 -- Pres : [124.951645]\n",
      "Actual : 117.0 -- Pres : [118.28403]\n",
      "Actual : 117.5 -- Pres : [117.61236]\n",
      "Actual : 121.0 -- Pres : [121.135216]\n",
      "Actual : 121.3 -- Pres : [123.05521]\n",
      "Actual : 125.0 -- Pres : [129.89735]\n",
      "Actual : 131.0 -- Pres : [133.2472]\n",
      "Actual : 133.0 -- Pres : [134.32756]\n",
      "Actual : 136.0 -- Pres : [138.16382]\n",
      "Actual : 140.0 -- Pres : [143.09607]\n",
      "Actual : 143.0 -- Pres : [144.12935]\n",
      "Actual : 147.0 -- Pres : [153.3438]\n",
      "Actual : 150.0 -- Pres : [152.02715]\n",
      "Actual : 153.0 -- Pres : [157.60367]\n",
      "Actual : 157.0 -- Pres : [163.58366]\n",
      "Actual : 160.0 -- Pres : [162.43466]\n",
      "Actual : 166.0 -- Pres : [168.38979]\n",
      "Actual : 169.0 -- Pres : [170.50539]\n",
      "Actual : 173.0 -- Pres : [176.11038]\n",
      "Actual : 178.0 -- Pres : [181.85297]\n",
      "Actual : 178.6 -- Pres : [180.73521]\n",
      "Actual : 178.6 -- Pres : [186.24146]\n",
      "Actual : 183.0 -- Pres : [190.10954]\n",
      "Actual : 186.0 -- Pres : [189.61252]\n",
      "Actual : 188.0 -- Pres : [188.82741]\n",
      "Actual : 192.0 -- Pres : [193.22992]\n",
      "Actual : 195.0 -- Pres : [201.1371]\n",
      "Actual : 195.3 -- Pres : [201.12938]\n",
      "Actual : 195.3 -- Pres : [196.31337]\n",
      "Actual : 198.0 -- Pres : [201.81892]\n",
      "Actual : 201.0 -- Pres : [199.97354]\n",
      "Actual : 205.0 -- Pres : [201.7922]\n",
      "Actual : 208.0 -- Pres : [206.30505]\n",
      "Actual : 211.0 -- Pres : [209.90816]\n",
      "Actual : 212.0 -- Pres : [209.88974]\n",
      "Actual : 209.0 -- Pres : [215.58748]\n",
      "Actual : 208.0 -- Pres : [217.79533]\n",
      "Actual : 208.0 -- Pres : [210.43411]\n",
      "Actual : 205.0 -- Pres : [209.46317]\n",
      "Actual : 198.0 -- Pres : [204.97433]\n",
      "Actual : 198.2 -- Pres : [201.8508]\n",
      "Actual : 187.0 -- Pres : [190.95813]\n",
      "Actual : 184.0 -- Pres : [189.21735]\n",
      "Actual : 184.0 -- Pres : [190.96283]\n",
      "Actual : 186.0 -- Pres : [195.09752]\n",
      "Actual : 194.0 -- Pres : [189.52531]\n",
      "Actual : 186.0 -- Pres : [188.01852]\n",
      "Actual : 175.0 -- Pres : [182.74358]\n",
      "Actual : 170.0 -- Pres : [174.19617]\n",
      "Actual : 168.0 -- Pres : [173.46321]\n",
      "Actual : 169.0 -- Pres : [169.72343]\n",
      "Actual : 169.3 -- Pres : [169.28247]\n",
      "Actual : 169.3 -- Pres : [169.32079]\n",
      "Actual : 166.0 -- Pres : [165.36723]\n",
      "Actual : 158.0 -- Pres : [154.94812]\n",
      "Actual : 150.0 -- Pres : [151.94258]\n",
      "Actual : 146.0 -- Pres : [150.75645]\n",
      "Actual : 144.0 -- Pres : [151.12048]\n",
      "Actual : 147.0 -- Pres : [147.87816]\n",
      "Actual : 143.0 -- Pres : [138.8582]\n",
      "Actual : 138.0 -- Pres : [139.01907]\n",
      "Actual : 133.0 -- Pres : [134.63814]\n",
      "Actual : 133.8 -- Pres : [134.3918]\n",
      "Actual : 132.0 -- Pres : [130.70146]\n",
      "Actual : 128.0 -- Pres : [123.01902]\n",
      "Actual : 119.0 -- Pres : [112.680214]\n",
      "Actual : 116.0 -- Pres : [109.701645]\n",
      "Actual : 109.0 -- Pres : [105.7507]\n",
      "Actual : 107.0 -- Pres : [105.6973]\n",
      "Actual : 107.0 -- Pres : [104.01311]\n",
      "Actual : 102.0 -- Pres : [102.25379]\n",
      "Actual : 96.0 -- Pres : [95.76825]\n",
      "Actual : 94.0 -- Pres : [92.91335]\n",
      "Actual : 96.0 -- Pres : [96.95357]\n",
      "Actual : 96.0 -- Pres : [97.24443]\n",
      "Actual : 96.0 -- Pres : [95.95124]\n",
      "Actual : 96.0 -- Pres : [96.23803]\n",
      "Actual : 95.0 -- Pres : [97.21341]\n",
      "Actual : 95.3 -- Pres : [94.649796]\n",
      "Actual : 97.0 -- Pres : [94.97454]\n",
      "Actual : 99.0 -- Pres : [98.74015]\n",
      "Actual : 101.0 -- Pres : [99.36501]\n",
      "Actual : 103.0 -- Pres : [103.384254]\n",
      "Actual : 104.0 -- Pres : [105.66624]\n",
      "Actual : 104.9 -- Pres : [107.72439]\n",
      "Actual : 107.0 -- Pres : [108.29818]\n",
      "Actual : 112.0 -- Pres : [114.9463]\n",
      "Actual : 115.0 -- Pres : [117.94037]\n",
      "Actual : 119.0 -- Pres : [120.302124]\n",
      "Actual : 124.0 -- Pres : [128.67639]\n",
      "Actual : 124.0 -- Pres : [129.08774]\n",
      "Actual : 125.0 -- Pres : [129.04974]\n",
      "Actual : 125.5 -- Pres : [127.988495]\n",
      "Actual : 127.0 -- Pres : [131.06816]\n",
      "Actual : 127.7 -- Pres : [135.40591]\n",
      "Actual : 127.7 -- Pres : [132.18666]\n",
      "Actual : 127.7 -- Pres : [131.94775]\n",
      "Actual : 127.7 -- Pres : [135.74623]\n",
      "Actual : 127.7 -- Pres : [133.92706]\n",
      "Actual : 127.7 -- Pres : [132.75197]\n",
      "Actual : 127.7 -- Pres : [132.19362]\n",
      "Actual : 127.7 -- Pres : [133.86444]\n",
      "Actual : 127.7 -- Pres : [135.0493]\n",
      "Actual : 127.7 -- Pres : [130.8697]\n",
      "Actual : 127.7 -- Pres : [132.10016]\n",
      "Actual : 127.7 -- Pres : [131.26883]\n",
      "Actual : 127.7 -- Pres : [131.48782]\n",
      "Actual : 127.7 -- Pres : [133.17812]\n",
      "Actual : 127.7 -- Pres : [131.85771]\n",
      "Actual : 127.7 -- Pres : [133.82115]\n",
      "Actual : 129.0 -- Pres : [134.305]\n",
      "Actual : 129.9 -- Pres : [133.51892]\n",
      "Actual : 129.9 -- Pres : [133.65286]\n",
      "Actual : 129.9 -- Pres : [135.74773]\n",
      "Actual : 129.9 -- Pres : [134.0836]\n",
      "Actual : 132.0 -- Pres : [135.3898]\n",
      "Actual : 135.0 -- Pres : [135.15376]\n",
      "Actual : 137.0 -- Pres : [140.31477]\n",
      "Actual : 140.0 -- Pres : [143.03307]\n",
      "Actual : 142.0 -- Pres : [148.6958]\n",
      "Actual : 142.2 -- Pres : [149.32773]\n",
      "Actual : 142.2 -- Pres : [136.95894]\n",
      "Actual : 48.0 -- Pres : [55.967598]\n",
      "Actual : 48.0 -- Pres : [58.590214]\n",
      "Actual : 48.0 -- Pres : [53.731483]\n",
      "Actual : 48.0 -- Pres : [54.18266]\n",
      "Actual : 48.0 -- Pres : [54.48529]\n",
      "Actual : 48.0 -- Pres : [54.619045]\n",
      "Actual : 48.0 -- Pres : [55.799385]\n",
      "Actual : 48.0 -- Pres : [53.38992]\n",
      "Actual : 48.0 -- Pres : [55.66071]\n",
      "Actual : 48.0 -- Pres : [57.430305]\n",
      "Actual : 48.0 -- Pres : [53.44225]\n",
      "Actual : 48.0 -- Pres : [52.551506]\n",
      "Actual : 48.0 -- Pres : [52.596058]\n",
      "Actual : 48.0 -- Pres : [53.9985]\n",
      "Actual : 48.0 -- Pres : [53.274376]\n",
      "Actual : 48.0 -- Pres : [54.963486]\n",
      "Actual : 48.0 -- Pres : [54.74078]\n",
      "Actual : 48.0 -- Pres : [55.48768]\n",
      "Actual : 48.0 -- Pres : [56.174965]\n",
      "Actual : 48.0 -- Pres : [52.443825]\n",
      "Actual : 48.0 -- Pres : [50.513824]\n",
      "Actual : 48.0 -- Pres : [57.620758]\n",
      "Actual : 48.0 -- Pres : [52.728474]\n",
      "Actual : 48.0 -- Pres : [55.717014]\n",
      "Actual : 48.0 -- Pres : [53.46373]\n",
      "Actual : 43.0 -- Pres : [50.966908]\n",
      "Actual : 40.0 -- Pres : [47.152325]\n",
      "Actual : 36.0 -- Pres : [43.1928]\n",
      "Actual : 29.0 -- Pres : [32.380898]\n",
      "Actual : 20.0 -- Pres : [22.041357]\n",
      "Actual : 17.0 -- Pres : [16.078201]\n",
      "Actual : 7.0 -- Pres : [7.688104]\n",
      "Actual : 3.0 -- Pres : [0.1393266]\n",
      "Actual : 3.9 -- Pres : [-3.2641172]\n",
      "Actual : 0.0 -- Pres : [-14.020986]\n",
      "Actual : 0.0 -- Pres : [-6.0397906]\n",
      "Actual : 0.0 -- Pres : [-0.29732606]\n",
      "Actual : 0.0 -- Pres : [-3.6945696]\n",
      "Actual : 0.0 -- Pres : [-6.797293]\n",
      "Actual : 0.0 -- Pres : [-9.451401]\n",
      "Actual : 0.0 -- Pres : [-7.06182]\n",
      "Actual : 0.0 -- Pres : [-10.56816]\n",
      "Actual : 0.0 -- Pres : [-4.2706957]\n",
      "Actual : 0.0 -- Pres : [-1.8110538]\n",
      "Actual : 0.0 -- Pres : [2.4273622]\n",
      "Actual : 0.0 -- Pres : [1.1036384]\n",
      "Actual : 0.0 -- Pres : [-1.8498487]\n",
      "Actual : 0.0 -- Pres : [-0.9966953]\n",
      "Actual : 0.0 -- Pres : [0.7359843]\n",
      "Actual : 0.0 -- Pres : [1.0680559]\n",
      "Actual : 0.0 -- Pres : [-3.2409692]\n",
      "Actual : 6.0 -- Pres : [5.9155207]\n",
      "Actual : 12.0 -- Pres : [11.748633]\n",
      "Actual : 14.0 -- Pres : [16.20831]\n",
      "Actual : 19.0 -- Pres : [22.465797]\n",
      "Actual : 20.0 -- Pres : [26.291735]\n",
      "Actual : 20.4 -- Pres : [25.713581]\n",
      "Actual : 20.4 -- Pres : [28.899418]\n",
      "Actual : 28.0 -- Pres : [35.32222]\n",
      "Actual : 28.7 -- Pres : [35.894516]\n",
      "Actual : 33.0 -- Pres : [38.82404]\n",
      "Actual : 33.9 -- Pres : [39.778618]\n",
      "Actual : 39.0 -- Pres : [44.346317]\n",
      "Actual : 39.8 -- Pres : [45.761574]\n",
      "Actual : 44.0 -- Pres : [49.376022]\n",
      "Actual : 49.0 -- Pres : [53.388317]\n",
      "Actual : 51.0 -- Pres : [52.072945]\n",
      "Actual : 57.0 -- Pres : [54.66645]\n",
      "Actual : 58.0 -- Pres : [58.571026]\n",
      "Actual : 63.0 -- Pres : [64.26897]\n",
      "Actual : 64.0 -- Pres : [66.16263]\n",
      "Actual : 66.0 -- Pres : [67.664986]\n",
      "Actual : 66.1 -- Pres : [69.278175]\n",
      "Actual : 69.0 -- Pres : [72.08301]\n",
      "Actual : 72.0 -- Pres : [74.89851]\n",
      "Actual : 76.0 -- Pres : [77.14124]\n",
      "Actual : 75.0 -- Pres : [78.71843]\n",
      "Actual : 79.0 -- Pres : [84.79546]\n",
      "Actual : 83.0 -- Pres : [87.58654]\n",
      "Actual : 87.0 -- Pres : [88.20337]\n",
      "Actual : 88.0 -- Pres : [89.15959]\n",
      "Actual : 92.0 -- Pres : [93.49635]\n",
      "Actual : 96.0 -- Pres : [97.05766]\n",
      "Actual : 96.0 -- Pres : [97.38353]\n",
      "Actual : 103.0 -- Pres : [103.57006]\n",
      "Actual : 106.0 -- Pres : [106.385315]\n",
      "Actual : 110.0 -- Pres : [108.89054]\n",
      "Actual : 112.0 -- Pres : [114.097855]\n",
      "Actual : 112.3 -- Pres : [116.36412]\n",
      "Actual : 114.0 -- Pres : [116.307465]\n",
      "Actual : 117.0 -- Pres : [120.54088]\n",
      "Actual : 117.7 -- Pres : [122.76959]\n",
      "Actual : 129.0 -- Pres : [129.57555]\n",
      "Actual : 132.0 -- Pres : [128.04018]\n",
      "Actual : 135.0 -- Pres : [133.61592]\n",
      "Actual : 138.0 -- Pres : [137.09872]\n",
      "Actual : 140.0 -- Pres : [140.1358]\n",
      "Actual : 140.9 -- Pres : [140.94543]\n",
      "Actual : 146.0 -- Pres : [146.16318]\n",
      "Actual : 152.0 -- Pres : [152.52528]\n",
      "Actual : 152.8 -- Pres : [152.57472]\n",
      "Actual : 154.0 -- Pres : [157.2283]\n",
      "Actual : 157.0 -- Pres : [157.92209]\n",
      "Actual : 161.0 -- Pres : [162.85178]\n",
      "Actual : 165.0 -- Pres : [160.50334]\n",
      "Actual : 165.4 -- Pres : [168.42484]\n",
      "Actual : 165.4 -- Pres : [166.30212]\n",
      "Actual : 165.4 -- Pres : [168.88757]\n",
      "Actual : 165.4 -- Pres : [165.02853]\n",
      "Actual : 165.4 -- Pres : [168.13245]\n",
      "Actual : 171.0 -- Pres : [174.44907]\n",
      "Actual : 171.2 -- Pres : [174.34369]\n",
      "Actual : 175.0 -- Pres : [174.9419]\n",
      "Actual : 177.0 -- Pres : [178.38872]\n",
      "Actual : 182.0 -- Pres : [183.95552]\n",
      "Actual : 184.0 -- Pres : [185.52641]\n",
      "Actual : 188.0 -- Pres : [187.84857]\n",
      "Actual : 191.0 -- Pres : [195.42416]\n",
      "Actual : 191.5 -- Pres : [190.1365]\n",
      "Actual : 191.5 -- Pres : [190.27977]\n",
      "Actual : 191.5 -- Pres : [195.42624]\n",
      "Actual : 191.5 -- Pres : [194.3224]\n",
      "Actual : 191.5 -- Pres : [190.18896]\n",
      "Actual : 188.0 -- Pres : [192.92966]\n",
      "Actual : 188.6 -- Pres : [193.86395]\n",
      "Actual : 188.6 -- Pres : [192.261]\n",
      "Actual : 188.6 -- Pres : [191.70146]\n",
      "Actual : 188.6 -- Pres : [193.28238]\n",
      "Actual : 188.6 -- Pres : [192.07074]\n",
      "Actual : 188.6 -- Pres : [196.98315]\n",
      "Actual : 188.6 -- Pres : [192.06674]\n",
      "Actual : 192.0 -- Pres : [191.70338]\n",
      "Actual : 195.0 -- Pres : [202.26526]\n",
      "Actual : 195.2 -- Pres : [197.97758]\n",
      "Actual : 195.2 -- Pres : [201.8727]\n",
      "Actual : 195.2 -- Pres : [200.87971]\n",
      "Actual : 195.2 -- Pres : [197.21426]\n",
      "Actual : 200.0 -- Pres : [203.49492]\n",
      "Actual : 201.0 -- Pres : [205.4573]\n",
      "Actual : 201.7 -- Pres : [209.17055]\n",
      "Actual : 198.0 -- Pres : [202.6558]\n",
      "Actual : 196.0 -- Pres : [200.4718]\n",
      "Actual : 191.0 -- Pres : [198.25871]\n",
      "Actual : 194.0 -- Pres : [197.53607]\n",
      "Actual : 194.0 -- Pres : [197.69366]\n",
      "Actual : 194.0 -- Pres : [196.50734]\n",
      "Actual : 194.0 -- Pres : [195.87479]\n",
      "Actual : 194.0 -- Pres : [198.58282]\n",
      "Actual : 194.0 -- Pres : [199.20529]\n",
      "Actual : 194.0 -- Pres : [198.51932]\n",
      "Actual : 194.0 -- Pres : [194.66444]\n",
      "Actual : 194.0 -- Pres : [195.21971]\n",
      "Actual : 188.0 -- Pres : [191.19704]\n",
      "Actual : 188.0 -- Pres : [188.23439]\n",
      "Actual : 188.0 -- Pres : [189.18404]\n",
      "Actual : 188.0 -- Pres : [187.68369]\n",
      "Actual : 186.0 -- Pres : [186.62308]\n",
      "Actual : 186.7 -- Pres : [185.72311]\n",
      "Actual : 186.7 -- Pres : [185.17609]\n",
      "Actual : 179.0 -- Pres : [179.30952]\n",
      "Actual : 176.0 -- Pres : [181.02905]\n",
      "Actual : 176.5 -- Pres : [180.15254]\n",
      "Actual : 170.0 -- Pres : [174.9882]\n",
      "Actual : 170.7 -- Pres : [171.41118]\n",
      "Actual : 166.0 -- Pres : [170.64304]\n",
      "Actual : 166.4 -- Pres : [166.87195]\n",
      "Actual : 160.0 -- Pres : [163.54495]\n",
      "Actual : 160.6 -- Pres : [162.06134]\n",
      "Actual : 150.0 -- Pres : [152.60977]\n",
      "Actual : 150.2 -- Pres : [152.43332]\n",
      "Actual : 146.0 -- Pres : [147.33823]\n",
      "Actual : 146.9 -- Pres : [145.13806]\n",
      "Actual : 139.0 -- Pres : [141.07489]\n",
      "Actual : 139.7 -- Pres : [144.581]\n",
      "Actual : 139.0 -- Pres : [142.96858]\n",
      "Actual : 139.5 -- Pres : [142.41762]\n",
      "Actual : 135.0 -- Pres : [138.5581]\n",
      "Actual : 135.5 -- Pres : [138.07932]\n",
      "Actual : 136.0 -- Pres : [137.21344]\n",
      "Actual : 136.1 -- Pres : [138.11905]\n",
      "Actual : 132.0 -- Pres : [132.98102]\n",
      "Actual : 132.1 -- Pres : [134.61665]\n",
      "Actual : 125.0 -- Pres : [125.5527]\n",
      "Actual : 125.8 -- Pres : [124.295425]\n",
      "Actual : 124.0 -- Pres : [123.1156]\n",
      "Actual : 124.2 -- Pres : [121.3582]\n",
      "Actual : 120.0 -- Pres : [121.273735]\n",
      "Actual : 120.3 -- Pres : [119.94523]\n",
      "Actual : 115.0 -- Pres : [115.61598]\n",
      "Actual : 108.0 -- Pres : [107.97841]\n",
      "Actual : 108.6 -- Pres : [107.36789]\n",
      "Actual : 106.0 -- Pres : [102.95185]\n",
      "Actual : 101.0 -- Pres : [100.67535]\n",
      "Actual : 97.0 -- Pres : [95.5396]\n",
      "Actual : 91.0 -- Pres : [89.95724]\n",
      "Actual : 88.0 -- Pres : [89.154945]\n",
      "Actual : 80.0 -- Pres : [80.25253]\n",
      "Actual : 80.6 -- Pres : [79.05905]\n",
      "Actual : 80.6 -- Pres : [78.68013]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_train)):\n",
    "    \n",
    "    print('Actual : '+ str(y_train[i])+' -- Pres : '+str(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('racerModel2.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.array([X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.1444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.16452"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = new_model.predict(XX)\n",
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "model2 = tf.keras.models.load_model('racerModel2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.1444"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.predict(XX)\n",
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
